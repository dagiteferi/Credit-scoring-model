{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Documents\\Dagii\\Credit-scoring-model\\week-6\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import Libraries and Configure Logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import os,sys\n",
    "import traceback\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(os.path.abspath('..')))\n",
    "# Import modules\n",
    "from scripts.model_explainability import load_or_preprocess_data, load_models, explain_logistic_regression, explain_random_forest, run_explainability_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Run Explainability Pipeline\n",
    "data_path = 'c:/Users/HP/Documents/Dagii/Credit-scoring-model/data/transformed_data_credit_scoring.csv' # Replace with your actual data path (e.g., 'credit_data.csv')\n",
    "model_dir = 'models'  # Directory where models are saved\n",
    "save_dir = 'model_explanations'  # Directory to save explanation plots\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 10:51:42 - scripts.model_explainability - INFO - Starting explainability pipeline\n",
      "2025-03-10 10:51:42 - scripts.model_explainability - INFO - Loading or preprocessing data\n",
      "2025-03-10 10:51:42 - scripts.model_explainability - INFO - Starting data preprocessing\n",
      "2025-03-10 10:51:43 - scripts.model_explainability - INFO - Dropped columns: ['TransactionId', 'BatchId', 'AccountId', 'SubscriptionId', 'CustomerId']\n",
      "2025-03-10 10:51:43 - scripts.model_explainability - INFO - Preprocessed data split: Train (76529, 52), Test (19133, 52)\n",
      "2025-03-10 10:51:43 - scripts.model_explainability - INFO - Loading saved models\n",
      "2025-03-10 10:51:43 - scripts.model_explainability - ERROR - Error loading models: [Errno 2] No such file or directory: 'models\\\\LogisticRegression_best_model.pkl'\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\HP\\Documents\\Dagii\\Credit-scoring-model\\scripts\\model_explainability.py\", line 125, in load_models\n",
      "    models[model_name] = joblib.load(model_path)\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\HP\\Documents\\Dagii\\Credit-scoring-model\\week-6\\Lib\\site-packages\\joblib\\numpy_pickle.py\", line 650, in load\n",
      "    with open(filename, 'rb') as f:\n",
      "         ^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'models\\\\LogisticRegression_best_model.pkl'\n",
      "\n",
      "2025-03-10 10:51:43 - scripts.model_explainability - ERROR - Failed to load models. Exiting.\n"
     ]
    }
   ],
   "source": [
    "explanations = run_explainability_pipeline(data_path, model_dir, save_dir)\n",
    "#logger.info(\"Explainability pipeline executed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "week-6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
